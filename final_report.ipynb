{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    <h2><center>Supreme Court Oral Arguments Outcome Prediction Team</center></h2>\n",
    "<h2 style=\"margin-top: -15px; margi-bottom: 10px;\"><center>Final Report</center></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Project and Team Information\n",
    "**Team members:** Federico Dominguez Molina, Jessup Jong, Chanteria Milner, and Michael Plunkett\n",
    "\n",
    "**Project summary:** The project uses historic United States Supreme Court cases to train natural language processing models to predict case rulings. \\\n",
    "**Project repository:** [Link](https://github.com/michplunkett/supreme-court-ml-predictions) \\\n",
    "**Project assumptions and things to know:**\n",
    "1. The number of unique roles within the advocates' file is too numerous to be helpful, so we merged them into 5 categories. While this merger may remove some variability and nuance in the file, we believe it will make it easier to derive meaningful conclusions.\n",
    "    - The groupings for the roles are as follows: inferred, for respondent, for partitioner, and for amicus curiae\n",
    "2. The years included within this data set are 2014 to 2019.\n",
    "3. The datasets included within the previously mentioned year range are ones where the winnings side was either 0 or 1 (no missing, etc.).\n",
    "\n",
    "**Models run:** Logistic Regression, XG Boost, and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyter_black'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Imports and setup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjupyter_black\u001b[39;00m\n\u001b[1;32m      4\u001b[0m jupyter_black\u001b[39m.\u001b[39mload()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jupyter_black'"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Table of Contents\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary Statistics\n",
    "\n",
    "[TAKE INFORMATION FROM THE FIRST CHECKPOINT AND MAYBE PRESENT IT AS A TABLE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "**What is a Logistic Regression model and what can you conclude from its results?**\n",
    "[WE SHOULD BE ABLE TO USE MOST OF THE PREVIOUSLY CREATED STUFF FROM REPORT 2]\n",
    "[2-3 sentences]\n",
    "\n",
    "**What are some limitations of the Logistic Regression model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What were we able to conclude from our use of the Logistic Regression model?**\n",
    "[2-3 sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code that runs the Logistic Regression model and creates visuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "**What is a Random Forest model and what can you conclude from its results?**\n",
    "[2-3 sentences]\n",
    "\n",
    "Random Forest is an ensemble of multiple decisions trees that uses a combination of bagging and random feature selection. Random Forest is trained through [bagging](https://link.springer.com/referenceworkentry/10.1007/978-1-4419-9863-7_612), or different bootstraps of training data, and returns the majority vote of multiple decision trees that split on a [random subset](https://link.springer.com/referenceworkentry/10.1007/978-1-4419-9863-7_602) of features. \n",
    "\n",
    "**What are some limitations of the Random Forest model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "It is harder to interpret a random forest model compared to a decision tree considering that we cannot follow through the decision process like how we would a decision tree. With bagging and random subsets of features, it takes a longer time and therefore more resources to train a random forest model.\n",
    "\n",
    "The bag of words CountVectorizer that we used only provides predictions based on word frequency. This does not account for more complex linguistic relationship between phrases and ideas. Using a more complex vectorizer such as tf-idf could help better account for complex phrases and ideas from utterances.\n",
    "\n",
    "**What were we able to conclude from our use of the Random Forest model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "We picked the random forest because we needed to capture the complex interactions among different words in unstrcutrued data, avoid overfitting by training on multiple decision trees, and rank the importance of different words on the predicted outcome. From the results, we can confirm the accuracy of the model in predicting case outcomes and see the importance of the different words. If we use this model for cross validation or out of sample data, we can also see how well the model generalizes and avoids overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code that runs the Random Forest model and creates visuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XG Boost\n",
    "\n",
    "**What is an XG Boost model and what can you conclude from its results?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What are some limitations of the XG Boost model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What were we able to conclude from our use of the Random Forest model?**\n",
    "[2-3 sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code that runs the XG Boost model and creates visuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summation\n",
    "\n",
    "**What model worked best for predicting case results based on utterances?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**How performant were each of the models (time, processing power, etc.)?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**If our constraints are time and computing power, which of the three models would be the best to implement?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What was a notable technical lesson you learned while creating this project?**\n",
    "\n",
    "**Federico:**\n",
    "**Jessup:**\n",
    "**Chanteria:**\n",
    "**Michael:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
