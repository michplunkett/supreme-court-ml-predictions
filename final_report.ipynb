{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "    <h2><center>Supreme Court Oral Arguments Outcome Prediction Team</center></h2>\n",
    "<h2 style=\"margin-top: -15px; margi-bottom: 10px;\"><center>Final Report</center></h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Project and Team Information\n",
    "**Team members:** Federico Dominguez Molina, Jessup Jong, Chanteria Milner, and Michael Plunkett\n",
    "\n",
    "**Project summary:** The project uses historic United States Supreme Court cases to train natural language processing models to predict case rulings. \\\n",
    "**Project repository:** [Link](https://github.com/michplunkett/supreme-court-ml-predictions) \\\n",
    "**Project assumptions and things to know:**\n",
    "1. The number of unique roles within the advocates' file is too numerous to be helpful, so we merged them into 5 categories. While this merger may remove some variability and nuance in the file, we believe it will make it easier to derive meaningful conclusions.\n",
    "    - The groupings for the roles are as follows: inferred, for respondent, for partitioner, and for amicus curiae\n",
    "2. The years included within this data set are 2014 to 2019.\n",
    "3. The datasets included within the previously mentioned year range are ones where the winnings side was either 0 or 1 (no missing, etc.).\n",
    "\n",
    "**Models run:** Logistic Regression, XG Boost, and Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 7) (4252756855.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 7\u001B[0;36m\u001B[0m\n\u001B[0;31m    1. The number of unique roles within the advocates' file is too numerous to be helpful, so we merged them into 5 categories. While this merger may remove some variability and nuance in the file, we believe it will make it easier to derive meaningful conclusions.\u001B[0m\n\u001B[0m                                                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unterminated string literal (detected at line 7)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyter_black'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m### Imports and setup\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjupyter_black\u001B[39;00m\n\u001B[1;32m      4\u001B[0m jupyter_black\u001B[38;5;241m.\u001B[39mload()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'jupyter_black'"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table of Contents\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summary Statistics\n",
    "\n",
    "[TAKE INFORMATION FROM THE FIRST CHECKPOINT AND MAYBE PRESENT IT AS A TABLE]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression\n",
    "\n",
    "**What is a Logistic Regression model and what can you conclude from its results?**\n",
    "[WE SHOULD BE ABLE TO USE MOST OF THE PREVIOUSLY CREATED STUFF FROM REPORT 2]\n",
    "[2-3 sentences]\n",
    "\n",
    "**What are some limitations of the Logistic Regression model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What were we able to conclude from our use of the Logistic Regression model?**\n",
    "[2-3 sentences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code that runs the Logistic Regression model and creates visuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest\n",
    "\n",
    "**What is a Random Forest model and what can you conclude from its results?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What are some limitations of the Random Forest model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What were we able to conclude from our use of the Random Forest model?**\n",
    "[2-3 sentences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code that runs the Random Forest model and creates visuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XG Boost\n",
    "\n",
    "**What is an XG Boost model and what can you conclude from its results?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What are some limitations of the XG Boost model?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What were we able to conclude from our use of the Random Forest model?**\n",
    "[2-3 sentences]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Code that runs the XG Boost model and creates visuals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summation\n",
    "\n",
    "**What model worked best for predicting case results based on utterances?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**How performant were each of the models (time, processing power, etc.)?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**If our constraints are time and computing power, which of the three models would be the best to implement?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What was a notable technical lesson you learned while creating this project?**\n",
    "\n",
    "**Federico:**\n",
    "**Jessup:**\n",
    "**Chanteria:**\n",
    "**Michael:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
