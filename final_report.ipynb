{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <h2><center>Supreme Court Oral Arguments Outcome Prediction Team</center></h2>\n",
    "<h2 style=\"margin-top: -15px; margi-bottom: 10px;\"><center>Final Report</center></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and Team Information\n",
    "**Team members:** Federico Dominguez Molina, Jessup Jong, Chanteria Milner, and Michael Plunkett\n",
    "\n",
    "**Project summary:** The project uses historic United States Supreme Court cases to train natural language processing models to predict case rulings. \\\n",
    "**Project repository:** [Link](https://github.com/michplunkett/supreme-court-ml-predictions) \\\n",
    "**Project assumptions and things to know:**\n",
    "1. The number of unique roles within the advocates' file is too numerous to be helpful, so we merged them into 5 categories. While this merger may remove some variability and nuance in the file, we believe it will make it easier to derive meaningful conclusions.\n",
    "    - The groupings for the roles are as follows: inferred, for respondent, for partitioner, and for amicus curiae\n",
    "2. The years included within this data set are 2014 to 2019.\n",
    "3. The datasets included within the previously mentioned year range are ones where the winnings side was either 0 or 1 (no missing, etc.).\n",
    "\n",
    "**Models run:** Logistic Regression, XG Boost, and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "    What the task is. \n",
    "    Overview (main things we've tried and learned)\n",
    "\n",
    "Data:\n",
    "    Data Analysis (Date Range 2014- 2019)\n",
    "    Filtering (5 years justices)\n",
    "\n",
    "Methodology: \n",
    "    Feature engineering\n",
    "    Modeling\n",
    "    How you are evaluating the models: F-1 metric\n",
    "    Hyperparameter tuning \n",
    "    How you trained it (epochs, test split)\n",
    "\n",
    "Results:\n",
    "    Analyze results of model\n",
    "    Hypothesize which model/hyperparametrs gives better results\n",
    "\n",
    "Conclusion: \n",
    "    Summary:\n",
    "    Limitation and future work:\n",
    "    Limitations of the data\n",
    "        Limitation of the task itself. (only given oral, not given supporting documents)\n",
    "        Lawyers often don't care about the outcome itself. Rather, they care often in how one arrives at that conclusion. In addition, the articulation and details in the reasoning in the decision is often more important in case. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "[TAKE INFORMATION FROM THE FIRST CHECKPOINT AND MAYBE PRESENT IT AS A TABLE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "**What is a Logistic Regression model?** \\\n",
    "Logistic regression in machine learning is a supervised learning model that predicts the probability of a binary outcome based on training data. It is called a \"supervised learning approach\" because the model is trained on data where the outcome is known. \n",
    "\n",
    "Logistic regression is also a classification model because it predicts the probability of a binary outcome, where it predicts if the petitioner, given the 'bag of words,' won or lost the case. It is also worth noting that regularization can be added to the model to prevent overfitting. Within our current model, we decided against using that feature.\n",
    "\n",
    "**What are some limitations of the Logistic Regression model?** \\\n",
    "Logistic regression is limited because it assumes a [linear relationship](https://careerfoundry.com/en/blog/data-analytics/what-is-logistic-regression/) between independent and dependent variables. It can also not consider the more complex relationships between the utterances and the Court decisions. It comes up short as the end-all-be-all model for our data since Supreme Court decisions and the speech uttered within them are not independent. Each case cannot be viewed within a vacuum but is instead influenced by precedents and the social trends of its time. Logistic regression may account for the association between verdicts and utterances. Still, it cannot explain or make any statements regarding causality.\n",
    "\n",
    "**What were we able to conclude from our use of the Logistic Regression model?** \\\n",
    "We applied logistic regression models to four different datasets and observed the below results. We used the following hyperparameters as defaults in our regression: a test size of `0.20`, a random state of 123, and a maximum of 1000 iterations.\n",
    "\n",
    "--Description of split in data\n",
    "\n",
    "-- Results in results (bar chart)\n",
    "\n",
    "**All Utterances:** This dataset comprises a bag of words created from all utterances in the cases between 2014 and 2019, including the judge, advocate, and adversary statements. The model achieved an accuracy of `54.05%`, slightly better than random chance.\n",
    "\n",
    "**Judge Utterances:** This dataset only focuses on a bag of words from judge statements. The model's accuracy was `52.05%`, underperforming compared to the model using all utterances.\n",
    "\n",
    "**Advocate Utterances:** Using a bag of words created solely from advocate statements, the model achieved an accuracy of `75.67%`, significantly outperforming the model using all utterances.\n",
    "\n",
    "**Adversary Utterances:** This dataset consists of a bag of words derived only from adversary statements. The model obtained an accuracy of `78.37%`, outperforming all other models and emerging as the best performer.\n",
    "\n",
    "In conclusion, models using advocate and adversary utterances independently have higher predictive power than models using judge utterances or a combination of all utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that runs the Logistic Regression model and creates visuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "**What is a Random Forest model and what can you conclude from its results?** \\\n",
    "Random Forest is an ensemble of multiple decision trees that combines bagging and random feature selection. Random Forest is trained through [bagging](https://link.springer.com/referenceworkentry/10.1007/978-1-4419-9863-7_612), or different bootstraps of training data and returns the majority vote of multiple decision trees that split on a [random subset](https://link.springer.com/referenceworkentry/10.1007/978-1-4419-9863-7_602) of features.\n",
    "\n",
    "**What are some limitations of the Random Forest model?** \\\n",
    "It is harder to interpret a Random Forest model than a decision tree because we cannot follow through the decision process like a decision tree. With bagging and random subsets of features, it takes longer and, therefore, more resources to train a random forest model.\n",
    "\n",
    "The predictions provided by the bag of words CountVectorizer are based solely on word frequency. This does not account for the complex linguistic relationship between phrases and ideas. A more complex vectorizer such as `tf-idf` could help better account for complex expressions and thoughts contained within the utterances.\n",
    "\n",
    "**What were we able to conclude from our use of the Random Forest model?** \\\n",
    "We picked the Random Forest model because we needed to capture the complex interactions among different words in unstructured data, to avoid overfitting our model by training on multiple decision trees, and to rank the importance of different words on the predicted outcome. We can confirm the model's accuracy by predicting case outcomes from the results, which gives us a view of each unique word's importance. If we were to use this model for cross-validation, or out-of-sample data, we could also see how well the model generalizes and avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that runs the Random Forest model and creates visuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost\n",
    "\n",
    "**What is an XG Boost model and what can you conclude from its results?** \n",
    "\n",
    "XG Boost, short for *Extreme Gradient Boosting* is a tree ensemble model that uses gradient boosting to minimize the loss function. In XG Boost, each tree is grown sequentially, taking into account the previous tree's residuals and reweighting the observations accordingly.\n",
    "\n",
    "XG Boost is called an \"ensemble model\" because it uses several \"weak learners\" (decision trees, in this case) to obtain a more robust model by adjusting the tree model on every iteration. It is different than Random Forest because, instead of averaging all of the weak learners' results to make the final prediction, it adjusts the model on every iteration by using the previous model's residuals as the new target variable. This allows the model to learn from its mistakes and improve on every iteration.\n",
    "\n",
    "**What are some limitations of the XG Boost model?**\n",
    "\n",
    "As with most ensemble models, XGBoost is very hard to interpret since it considers multiple decision trees to get the final prediction. \n",
    "\n",
    "One crucial limitation of the XG Boost model is that it can easily lead to overfitting if the parameters are not properly tuned. This means that XG Boost may practically 'learn' the training data, but may not generalize well to unseen data. The model is also very sensible to outliers and noisy data, which can affect its overall performance.\n",
    "\n",
    "**What were we able to conclude from our use of the XG Boost model?** \n",
    "\n",
    "A crucial insight is that ensemble models tend to perform better than 'single' models. In this case, XG Boost uses several decision trees to make the final prediction while adjusting the model on every iteration. This allows the model to learn from its mistakes and improve on every iteration, which leads to a better overall performance.\n",
    "\n",
    "On the other hand, however, ease of interpretation is lost, and a lengthy finetuning process is necessary to get the best set of hyperparameters for our context.\n",
    "\n",
    "<!-- Can print out IDs of which ones are misclassified. Point out /trace back to the data.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model Class\n",
    "from supreme_court_predictions.models.xg_boost import (\n",
    "    XGBoost,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bag of words\n",
      "Starting the XGBoost model\n",
      "------------------------------------------\n",
      "Running a gradient boosted tree model on case_aggregations...\n",
      "Accuracy score: 0.5675675675675675\n",
      "F1 score: 0.68\n",
      "------------------------------------------\n",
      "Creating bag of words\n",
      "Starting the XGBoost model\n",
      "------------------------------------------\n",
      "Running a gradient boosted tree model on judge_aggregations...\n",
      "Accuracy score: 0.547945205479452\n",
      "F1 score: 0.6972477064220183\n",
      "------------------------------------------\n",
      "Creating bag of words\n",
      "Starting the XGBoost model\n",
      "------------------------------------------\n",
      "Running a gradient boosted tree model on advocate_aggregations...\n",
      "Accuracy score: 0.8108108108108109\n",
      "F1 score: 0.8600000000000001\n",
      "------------------------------------------\n",
      "Creating bag of words\n",
      "Starting the XGBoost model\n",
      "------------------------------------------\n",
      "Running a gradient boosted tree model on adversary_aggregations...\n",
      "Accuracy score: 0.8243243243243243\n",
      "F1 score: 0.8631578947368421\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'case_aggregations': 0.5675675675675675,\n",
       "  'judge_aggregations': 0.547945205479452,\n",
       "  'advocate_aggregations': 0.8108108108108109,\n",
       "  'adversary_aggregations': 0.8243243243243243},\n",
       " {'case_aggregations': 0.68,\n",
       "  'judge_aggregations': 0.6972477064220183,\n",
       "  'advocate_aggregations': 0.8600000000000001,\n",
       "  'adversary_aggregations': 0.8631578947368421},\n",
       " {'case_aggregations': array([[ 8, 19],\n",
       "         [13, 34]], dtype=int64),\n",
       "  'judge_aggregations': array([[ 2, 24],\n",
       "         [ 9, 38]], dtype=int64),\n",
       "  'advocate_aggregations': array([[17, 10],\n",
       "         [ 4, 43]], dtype=int64),\n",
       "  'adversary_aggregations': array([[20,  7],\n",
       "         [ 6, 41]], dtype=int64)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run model\n",
    "xgboost_model = XGBoost(debug_mode=True)\n",
    "xgboost_model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Parameters\n",
    "eta=0.3\n",
    "subsample=1\n",
    "max_depth=7\n",
    "n_estimators=100\n",
    "\n",
    "\n",
    "# Create an array of different values to test\n",
    "eta_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "subsample_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "max_depth_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing eta value: 0.1\n"
     ]
    }
   ],
   "source": [
    "accuracy_dicts = []\n",
    "f1_dicts = []\n",
    "confusion_matrix_dicts = []\n",
    "\n",
    "for eta_value in eta_values:\n",
    "    print(f\"Testing eta value: {eta_value}\" )\n",
    "    xgboost_model = XGBoost(debug_mode=False, eta=eta_value)\n",
    "    xgboost_model.run()\n",
    "\n",
    "    accuracy_dicts.append(xgboost_model.accuracies)\n",
    "    f1_dicts.append(xgboost_model.f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_aggregations': 0.5675675675675675,\n",
       " 'judge_aggregations': 0.547945205479452,\n",
       " 'advocate_aggregations': 0.8108108108108109,\n",
       " 'adversary_aggregations': 0.8243243243243243}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_aggregations': 0.68,\n",
       " 'judge_aggregations': 0.6972477064220183,\n",
       " 'advocate_aggregations': 0.8600000000000001,\n",
       " 'adversary_aggregations': 0.8631578947368421}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'case_aggregations': array([[ 8, 19],\n",
       "        [13, 34]], dtype=int64),\n",
       " 'judge_aggregations': array([[ 2, 24],\n",
       "        [ 9, 38]], dtype=int64),\n",
       " 'advocate_aggregations': array([[17, 10],\n",
       "        [ 4, 43]], dtype=int64),\n",
       " 'adversary_aggregations': array([[20,  7],\n",
       "        [ 6, 41]], dtype=int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model.confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summation\n",
    "\n",
    "**What model worked best for predicting case results based on utterances?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**How performant were each of the models (time, processing power, etc.)?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**If our constraints are time and computing power, which of the three models would be the best to implement?**\n",
    "[2-3 sentences]\n",
    "\n",
    "**What was a notable technical lesson you learned while creating this project?**\n",
    "\n",
    "**Federico:** \n",
    "\n",
    "**Jessup:**\n",
    "Compared to manually programming each machine learning model, I learned that using sklearn is drastically easier. This frees up a lot of time to work on optimizing the model through hyperparameters and picking amongst many available models to best fit the different kind of data we are training on. \n",
    "\n",
    "**Chanteria:**\n",
    "\n",
    "**Michael:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
